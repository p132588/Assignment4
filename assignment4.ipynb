{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjs74Iz02KAe0dhH89cuAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p132588/Assignment4/blob/main/assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 4**"
      ],
      "metadata": {
        "id": "fQ-pJRp8f2fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the necessary modules from PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "qFETMDEZIsaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parseInput(line):\n",
        "    fields = line.split('|')\n",
        "    return Row(user_id=int(fields[0]), age=int(fields[1]), gender=fields[2], occupation=fields[3], zip=fields[4])"
      ],
      "metadata": {
        "id": "oxXb_mF4IxA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    spark = SparkSession.builder.appName(\"CassandraIntegration\").config(\"spark.cassandra.connection.host\", \"127.0.0.1\").getOrCreate()\n",
        "\n",
        "    lines_users = spark.sparkContext.textFile(\"hdfs:///user/maria_dev/ml-100k/u.user\")\n",
        "    users = lines_users.map(parseInput)\n",
        "    usersDataset = spark.createDataFrame(users)\n",
        "\n",
        "    usersDataset.write\\\n",
        "        .format(\"org.apache.spark.sql.cassandra\")\\\n",
        "        .mode('append')\\\n",
        "        .options(table=\"users\", keyspace=\"movielens\")\\\n",
        "        .save()\n",
        "\n",
        "    readUsers = spark.read\\\n",
        "    .format(\"org.apache.spark.sql.cassandra\")\\\n",
        "    .options(table=\"users\", keyspace=\"movielens\")\\\n",
        "    .load()\n",
        "    readUsers.createOrReplaceTempView(\"users\")\n",
        "\n",
        "    lines_ratings = spark.sparkContext.textFile(\"hdfs:///user/maria_dev/ml-100k/u.data\")\n",
        "    ratings = lines_ratings.map(lambda line: line.split('\\t')).map(lambda x: Row(user_id=int(x[0]), movie_id=int(x[1]), rating=float(x[2])))\n",
        "    ratingsDataset = spark.createDataFrame(ratings)\n",
        "\n",
        "    lines_item = spark.sparkContext.textFile(\"hdfs:///user/maria_dev/ml-100k/u.item\")\n",
        "    items = lines_item.map(lambda line: line.split('|')).map(lambda x: Row(user_id=int(x[0]), movie_name=x[1]))\n",
        "    itemssDataset = spark.createDataFrame(items)\n",
        "    #question1 Calculate the average rating for each movie.\n",
        "    movies_avg_rating = ratingsDataset.groupby(\"movie_id\").agg(functions.round(functions.avg(\"rating\"),2))\n",
        "    #question2 Identify the top ten movies with the highest average ratings.\n",
        "    average_ratings = ratingsDataset.groupBy('movie_id').agg(functions.avg('rating').alias('avg_rating')).orderBy('avg_rating', ascending=False).limit(10)\n",
        "    average_ratings.show()\n",
        "    #question3 Find the users who have rated at least 50 movies and identify their favourite movie genres.\n",
        "    windowSpec = Window.partitionBy\n",
        "    user_rating_50 = ratingsDataset.withColumn(\"sum\",functions.count(\"*\").over(Window.partitionBy(\"user_id\"))).where(\"sum > 50\")\n",
        "    user_like_movie = user_rating_50.join(itemssDataset,\"user_id\",how='right').dropDuplicates([\"user_id\"]).select(\"user_id\",\"movie_name\")\n",
        "    user_like_movie.show()\n",
        "    #question4 Find all the users with age that is less than 20 years old.\n",
        "    sqlDF = spark.sql(\"SELECT * FROM users WHERE age < 20\")\n",
        "    sqlDF.show()\n",
        "    #question5  Find all the users who have the occupation “scientist” and their age is between 30 and 40 years old.\n",
        "    scientist_users = spark.sql(\"SELECT * FROM USERS where occupation = 'scientist' AND age >= 30 AND age <= 409\")\n",
        "    scientist_users.show()\n",
        "    spark.stop()"
      ],
      "metadata": {
        "id": "3GYQNPt5I0m-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}